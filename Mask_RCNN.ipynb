{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask_RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE1FL6ZPzd_e",
        "outputId": "496018c2-66eb-4dbe-cb46-573ef62888c4"
      },
      "source": [
        "#MOUNT GDRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5xeP8zjGus-"
      },
      "source": [
        "from bs4 import BeautifulSoup \n",
        "# Reading the data inside the xml file to a variable under the name  data\n",
        "with open('/content/dataset/V000/V000/I00000.xml', 'r') as f:\n",
        "    data = f.read() \n",
        "# Passing the stored data inside the beautifulsoup parser \n",
        "bs_data = BeautifulSoup(data, 'xml') \n",
        "print(bs_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir-sBexKHDGO"
      },
      "source": [
        "with open('/content/annot/annotations-xml/set11/V000/I00000.xml', 'r') as f:\n",
        "    data = f.read() \n",
        "\n",
        "# Passing the stored data inside the beautifulsoup parser \n",
        "bs_data = BeautifulSoup(data, 'xml') \n",
        "print(bs_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqcWWLaANgAS"
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFdDWijqN5Rm"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "os.chdir('/content/Mask_RCNN')\n",
        "!pwd\n",
        "# ROOT_DIR = os.path.abspath(\"\")\n",
        "# print (ROOT_DIR)\n",
        "# sys.path.append(ROOT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PryTrYulPH3C"
      },
      "source": [
        "!python '/content/Mask_RCNN/setup.py' install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmxdJWvYz9zE"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/annotations-xml.zip\" -d \"/content/dataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTHYg2p60Wvd"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/Data/Training/set03.zip\" -d \"/content/dataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trYxW_ZY1vcS"
      },
      "source": [
        "def histogram_equalization_check(img_in):\n",
        "# segregate color streams\n",
        "    b,g,r = cv2.split(img_in)\n",
        "    h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n",
        "    h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n",
        "    h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])\n",
        "# calculate cdf    \n",
        "    cdf_b = np.cumsum(h_b)  \n",
        "    cdf_g = np.cumsum(h_g)\n",
        "    cdf_r = np.cumsum(h_r)\n",
        "    \n",
        "# mask all pixels with value=0 and replace it with mean of the pixel values \n",
        "    cdf_m_b = np.ma.masked_equal(cdf_b,0)\n",
        "    cdf_m_b = (cdf_m_b - cdf_m_b.min())*255/(cdf_m_b.max()-cdf_m_b.min())\n",
        "    cdf_final_b = np.ma.filled(cdf_m_b,0).astype('uint8')\n",
        "  \n",
        "    cdf_m_g = np.ma.masked_equal(cdf_g,0)\n",
        "    cdf_m_g = (cdf_m_g - cdf_m_g.min())*255/(cdf_m_g.max()-cdf_m_g.min())\n",
        "    cdf_final_g = np.ma.filled(cdf_m_g,0).astype('uint8')\n",
        "    cdf_m_r = np.ma.masked_equal(cdf_r,0)\n",
        "    cdf_m_r = (cdf_m_r - cdf_m_r.min())*255/(cdf_m_r.max()-cdf_m_r.min())\n",
        "    cdf_final_r = np.ma.filled(cdf_m_r,0).astype('uint8')\n",
        "# merge the images in the three channels\n",
        "    img_b = cdf_final_b[b]\n",
        "    img_g = cdf_final_g[g]\n",
        "    img_r = cdf_final_r[r]\n",
        "  \n",
        "    img_out = cv2.merge((img_b, img_g, img_r))\n",
        "# validation\n",
        "    equ_b = cv2.equalizeHist(b)\n",
        "    equ_g = cv2.equalizeHist(g)\n",
        "    equ_r = cv2.equalizeHist(r)\n",
        "    equ = cv2.merge((equ_b, equ_g, equ_r))\n",
        "    #print(equ)\n",
        "    #cv2.imwrite('output_name.png', equ)\n",
        "    return img_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW_O5-47NTr6"
      },
      "source": [
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from mrcnn.utils import Dataset\n",
        " \n",
        "class KAISTDataset(Dataset):\n",
        "\t# load the dataset definitions\n",
        "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
        "\t\t# define one class\n",
        "\t\tself.add_class(\"dataset\", 1, \"person\")\n",
        "\t\timages_dir = dataset_dir + '/images/'\n",
        "\t\tannotations_dir = dataset_dir + '/annot/'\n",
        "\t\t# find all images\n",
        "\t\tfor filename in listdir(images_dir):\n",
        "\t\t\t# extract image id\n",
        "\t\t\timage_id = filename[:-4]\n",
        "\t\t\timg_path = images_dir + filename\n",
        "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
        "\t\t\t# add to dataset\n",
        "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        " \n",
        "\t# extract bounding boxes from an annotation file\n",
        "\tdef extract_boxes(self, filename):\n",
        "\t\t# load and parse the file\n",
        "\t\ttree = ElementTree.parse(filename)\n",
        "\t\t# get the root of the document\n",
        "\t\troot = tree.getroot()\n",
        "\t\t# extract each bounding box\n",
        "\t\tboxes = list()\n",
        "\t\tfor box in root.findall('.//bndbox'):\n",
        "\t\t\txmin = round(float(box.find('xmin').text))\n",
        "\t\t\tymin = round(float(box.find('ymin').text))\n",
        "\t\t\txmax = round(float(box.find('xmax').text))\n",
        "\t\t\tymax = round(float(box.find('ymax').text))\n",
        "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
        "\t\t\tboxes.append(coors)\n",
        "\t\t# extract image dimensions\n",
        "\t\twidth = int(root.find('.//size/width').text)\n",
        "\t\theight = int(root.find('.//size/height').text)\n",
        "\t\treturn boxes, width, height\n",
        " \n",
        "\t# load the masks for an image\n",
        "\tdef load_mask(self, image_id):\n",
        "\t\t# get details of image\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\t# define box file location\n",
        "\t\tpath = info['annotation']\n",
        "\t\t# load XML\n",
        "\t\tboxes, w, h = self.extract_boxes(path)\n",
        "\t\t# create one array for all masks, each on a different channel\n",
        "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\t\t# create masks\n",
        "\t\tclass_ids = list()\n",
        "\t\tfor i in range(len(boxes)):\n",
        "\t\t\tbox = boxes[i]\n",
        "\t\t\trow_s, row_e = box[1], box[3]\n",
        "\t\t\tcol_s, col_e = box[0], box[2]\n",
        "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
        "\t\t\tclass_ids.append(self.class_names.index('person'))\n",
        "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
        " \n",
        "\t# load an image reference\n",
        "\tdef image_reference(self, image_id):\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\treturn info['path']\n",
        " #/content/dataset/V000\n",
        "# train set\n",
        "train_set = KAISTDataset()\n",
        "train_set.load_dataset('/content/betaset', is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        " \n",
        "# test/val set\n",
        "test_set = KAISTDataset()\n",
        "test_set.load_dataset('/content/betaset', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHPhsNf-PVav"
      },
      "source": [
        "image_id = 0\n",
        "image = train_set.load_image(image_id)\n",
        "print(image.shape)\n",
        "# load image mask\n",
        "mask, class_ids = train_set.load_mask(image_id)\n",
        "print(mask.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKvyqnhBygkU"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y421y9qHxs6U"
      },
      "source": [
        "img = cv2.imread('/content/betaset/images/I00160.jpg')\n",
        "img1 = cv2.imread('/content/dataset/V000/lwir/I00160.jpg')\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(img1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WjFOUlAS3-I"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot image\n",
        "plt.imshow(image)\n",
        "# plot mask\n",
        "plt.imshow(mask[:, :, 0], cmap='gray', alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_sd3Lr8TEWt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(9):\n",
        "\t# define subplot\n",
        "\tplt.subplot(330 + 1 + i)\n",
        "\t# plot raw pixel data\n",
        "\timage = train_set.load_image(i)\n",
        "\tplt.imshow(image)\n",
        "\t# plot all masks\n",
        "\tmask, _ = train_set.load_mask(i)\n",
        "\tfor j in range(mask.shape[2]):\n",
        "\t\tplt.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
        "# show the figure\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuH3fc3jTUbT"
      },
      "source": [
        "for image_id in train_set.image_ids:\n",
        "\t# load image info\n",
        "\tinfo = train_set.image_info[image_id]\n",
        "\t# display on the console\n",
        "\tprint(info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSk6Fzr0TjJW"
      },
      "source": [
        "image_id = 1\n",
        "from mrcnn.utils import extract_bboxes\n",
        "from mrcnn.visualize import display_instances\n",
        "# load the image\n",
        "image = train_set.load_image(image_id)\n",
        "# load the masks and the class ids\n",
        "mask, class_ids = train_set.load_mask(image_id)\n",
        "# extract bounding boxes from the masks\n",
        "bbox = extract_bboxes(mask)\n",
        "# display image with masks and bounding boxes\n",
        "display_instances(image, bbox, mask, class_ids, train_set.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWv2n4fZV254"
      },
      "source": [
        "!pip uninstall keras -y\n",
        "!pip uninstall keras-nightly -y\n",
        "!pip uninstall keras-Preprocessing -y\n",
        "!pip uninstall keras-vis -y\n",
        "!pip uninstall tensorflow -y\n",
        "!pip uninstall h5py -y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Jb3tAnV8DS"
      },
      "source": [
        "!pip install tensorflow==1.13.1\n",
        "!pip install keras==2.0.8\n",
        "!pip install h5py==2.10.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJXDVA3SUAB2"
      },
      "source": [
        "from mrcnn.config import Config\n",
        "class KAISTConfig(Config):\n",
        "  NAME = 'KAIST_cfg'\n",
        "  NUM_CLASSES = 1+1\n",
        "  STEPS_PER_EPOCH = 4400\n",
        "config = KAISTConfig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlq1nkOVUrzA"
      },
      "source": [
        "from mrcnn.model import MaskRCNN\n",
        "model = MaskRCNN(mode = 'training', model_dir = './' , config = config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKPktCojWfmM"
      },
      "source": [
        "# load weights (mscoco)\n",
        "model.load_weights('/content/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnlDt1oxXM08"
      },
      "source": [
        "# fit a mask rcnn on the kangaroo dataset\n",
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "\n",
        "# class that defines and loads the kangaroo dataset\n",
        "class KAISTDataset(Dataset):\n",
        "\t# load the dataset definitions\n",
        "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
        "\t\t# define one class\n",
        "\t\tself.add_class(\"dataset\", 1, \"person\")\n",
        "\t\t# define data locations\n",
        "\t\timages_dir = dataset_dir + '/images/'\n",
        "\t\tannotations_dir = dataset_dir + '/annot/'\n",
        "\t\t# find all images\n",
        "\t\tcount = 0\n",
        "\t\tfor filename in listdir(images_dir):\n",
        "\t\t\tcount += 1\n",
        "\t\t\tif count % 50 != 0:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# extract image id\n",
        "\t\t\timage_id = filename[:-4]\n",
        "\t\t\timg_path = images_dir + filename\n",
        "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
        "\t\t\t# add to dataset\n",
        "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        "\t \n",
        "\tdef load_test_dataset(self, dataset_dir, is_train=True):\n",
        "\t\t# define one class\n",
        "\t\tself.add_class(\"dataset\", 1, \"person\")\n",
        "\t\t# define data locations\n",
        "\t\timages_dir = dataset_dir + '/images/'\n",
        "\t\tannotations_dir = dataset_dir + '/annot/'\n",
        "\t\t# find all images\n",
        "\t\tcount = 0\n",
        "\t\tfor filename in listdir(images_dir):\n",
        "\t\t\tcount += 1\n",
        "\t\t\tif count % 80 != 0:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# extract image id\n",
        "\t\t\timage_id = filename[:-4]\n",
        "\t\t\timg_path = images_dir + filename\n",
        "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
        "\t\t\t# add to dataset\n",
        "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        "\n",
        "\t# extract bounding boxes from an annotation file\n",
        "\tdef extract_boxes(self, filename):\n",
        "\t\t# load and parse the file\n",
        "\t\ttree = ElementTree.parse(filename)\n",
        "\t\t# get the root of the document\n",
        "\t\troot = tree.getroot()\n",
        "\t\t# extract each bounding box\n",
        "\t\tboxes = list()\n",
        "\t\tfor box in root.findall('.//bndbox'):\n",
        "\t\t\txmin = round(float(box.find('xmin').text))\n",
        "\t\t\tymin = round(float(box.find('ymin').text))\n",
        "\t\t\txmax = round(float(box.find('xmax').text))\n",
        "\t\t\tymax = round(float(box.find('ymax').text))\n",
        "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
        "\t\t\tboxes.append(coors)\n",
        "\t\t# extract image dimensions\n",
        "\t\twidth = int(root.find('.//size/width').text)\n",
        "\t\theight = int(root.find('.//size/height').text)\n",
        "\t\treturn boxes, width, height\n",
        "\n",
        "\t# load the masks for an image\n",
        "\tdef load_mask(self, image_id):\n",
        "\t\t# get details of image\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\t# define box file location\n",
        "\t\tpath = info['annotation']\n",
        "\t\t# load XML\n",
        "\t\tboxes, w, h = self.extract_boxes(path)\n",
        "\t\t# create one array for all masks, each on a different channel\n",
        "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\t\t# create masks\n",
        "\t\tclass_ids = list()\n",
        "\t\tfor i in range(len(boxes)):\n",
        "\t\t\tbox = boxes[i]\n",
        "\t\t\trow_s, row_e = box[1], box[3]\n",
        "\t\t\tcol_s, col_e = box[0], box[2]\n",
        "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
        "\t\t\tclass_ids.append(self.class_names.index('person'))\n",
        "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "\t# load an image reference\n",
        "\tdef image_reference(self, image_id):\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\treturn info['path']\n",
        "\n",
        "# define a configuration for the model\n",
        "class KAISTConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"KAIST_cfg\"\n",
        "\t# number of classes (background + kangaroo)\n",
        "\tNUM_CLASSES = 1 + 1\n",
        "\t# number of training steps per epoch\n",
        "\tSTEPS_PER_EPOCH = 250\n",
        "\n",
        "# prepare train set\n",
        "train_set = KAISTDataset()\n",
        "train_set.load_dataset('/content/betaset', is_train=True)\n",
        "train_set.prepare()\n",
        "print('Train: %d' % len(train_set.image_ids))\n",
        "# prepare test/val set\n",
        "test_set = KAISTDataset()\n",
        "test_set.load_test_dataset('/content/betaset', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))\n",
        "# prepare config\n",
        "config = KAISTConfig()\n",
        "config.display()\n",
        "# define the model\n",
        "model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
        "# load weights (mscoco) and exclude the output layers\n",
        "model.load_weights('/content/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "# train weights (output layers or 'heads')\n",
        "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=5, layers='heads')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zxkoEqwxFAG"
      },
      "source": [
        "#------------------------------------------------------After Rohit Gone----------------------------------------------\n",
        "# define the prediction configuration\n",
        "class PredictionConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"KAIST_cfg\"\n",
        "\t# number of classes (background + kangaroo)\n",
        "\tNUM_CLASSES = 1 + 1\n",
        "\t# simplify GPU config\n",
        "\tGPU_COUNT = 1\n",
        "\tIMAGES_PER_GPU = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov5UEOVtxLcs"
      },
      "source": [
        "# create config\n",
        "cfg = PredictionConfig()\n",
        "# define the model\n",
        "model = MaskRCNN(mode='inference', model_dir='./', config=cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNTdLm0fxPXy"
      },
      "source": [
        "# load model weights\n",
        "model.load_weights('./kaist_cfg20211115T0947/mask_rcnn_kaist_cfg_{epoch:04d}.h5', by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv5N9dJcPbbM"
      },
      "source": [
        "from mrcnn.model import load_image_gt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYz30XZZxTSy"
      },
      "source": [
        "# load image, bounding boxes and masks for the image id\n",
        "image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytekamnBxaCd"
      },
      "source": [
        "# convert pixel values (e.g. center)\n",
        "scaled_image = mold_image(image, cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGxC6fbGxc_a"
      },
      "source": [
        "sample = expand_dims(scaled_image, 0)\n",
        "# make prediction\n",
        "yhat = model.detect(sample, verbose=0)\n",
        "# extract results for first sample\n",
        "r = yhat[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zONi1YMXxewv"
      },
      "source": [
        "# calculate statistics, including AP\n",
        "AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm-hzZoSxg5o"
      },
      "source": [
        "# calculate the mAP for a model on a given dataset\n",
        "def evaluate_model(dataset, model, cfg):\n",
        "\tAPs = list()\n",
        "\tfor image_id in dataset.image_ids:\n",
        "\t\t# load image, bounding boxes and masks for the image id\n",
        "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)\n",
        "\t\t# extract results for first sample\n",
        "\t\tr = yhat[0]\n",
        "\t\t# calculate statistics, including AP\n",
        "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "\t\t# store\n",
        "\t\tAPs.append(AP)\n",
        "\t# calculate the mean AP across all images\n",
        "\tmAP = mean(APs)\n",
        "\treturn mAP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axvZ0r9ixi9B"
      },
      "source": [
        "# evaluate model on training dataset\n",
        "train_mAP = evaluate_model(train_set, model, cfg)\n",
        "print(\"Train mAP: %.3f\" % train_mAP)\n",
        "# evaluate model on test dataset\n",
        "test_mAP = evaluate_model(test_set, model, cfg)\n",
        "print(\"Test mAP: %.3f\" % test_mAP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU2v6UYRxrtw"
      },
      "source": [
        "while True:pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu-ELv_fxLJK"
      },
      "source": [
        "plt."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}